{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# *Classification Network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sep=\",;,;,;\"\n",
    "def wrapper(learning_rate, dropout):\n",
    "    from hops import hdfs\n",
    "    #TODO: add network here with all the import within necessary for the code within the function\n",
    "    \n",
    "    acc=0.87\n",
    "    hdfs.log(sep+str(acc)+sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# *Parallely executes and returns list of accuracies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(v):\n",
    "    if sep in v[\"_c0\"]:\n",
    "        i = v[\"_c0\"].find(sep)\n",
    "        substr = v[\"_c0\"][i+len(sep):]\n",
    "        i = substr.find(sep)\n",
    "        return [substr[:i]]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def get_all_accuracies(tensorboard_hdfs_logdir, args_dict, number_params):\n",
    "    from hops import hdfs\n",
    "    print(tensorboard_hdfs_logdir)\n",
    "    results=[]\n",
    "    for i in range(number_params):\n",
    "        path_to_log=tensorboard_hdfs_logdir+\"/\"\n",
    "        for k in args_dict.keys():\n",
    "            path_to_log+=k+\"=\"+str(args_dict[k][i])+\".\"\n",
    "        path_to_log+=\"log\"\n",
    "        print(\"Path to log: \")\n",
    "        print(path_to_log)\n",
    "        raw = spark.read.csv(path_to_log, sep=\"\\n\")\n",
    "        #raw.show(10)\n",
    "        #raw.count()\n",
    "        r = raw.rdd.flatMap(lambda v: get_accuracy(v)).collect()\n",
    "        results.extend(r)\n",
    "\n",
    "    #print(results)\n",
    "    return [float(res) for res in results]\n",
    "\n",
    "def execute_all(args_dict):\n",
    "    from hops import tflauncher\n",
    "    number_params=2\n",
    "    tensorboard_hdfs_logdir = tflauncher.launch(spark, wrapper, args_dict)\n",
    "    return get_all_accuracies(tensorboard_hdfs_logdir, args_dict,number_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# *Evolutionary algorithm for hyperparameter optimization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Define dict for hyperparameters\n",
    "#args_dict = {'learning_rate': [0.001,0.002,2], 'dropout': [0.45,0.05,3]}\n",
    "#TODO: add here evolutive algorithm\n",
    "#number_params = 3\n",
    "#accuracies = execute_all(args_dict,number_params)\n",
    "#print accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
