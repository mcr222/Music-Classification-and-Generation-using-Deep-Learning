{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep=\",;,;,;\"\n",
    "def wrapper(learning_rate, dropout):\n",
    "    from hops import hdfs\n",
    "    #TODO: add network here with all the import within necessary for the code within the function\n",
    "    \n",
    "    acc=0.87\n",
    "    hdfs.log(sep+str(acc)+sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallely executes and returns list of accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(v):\n",
    "    if sep in v[\"_c0\"]:\n",
    "        i = v[\"_c0\"].find(sep)\n",
    "        substr = v[\"_c0\"][i+len(sep):]\n",
    "        i = substr.find(sep)\n",
    "        return [substr[:i]]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def get_all_accuracies(tensorboard_hdfs_logdir, args_dict, number_params):\n",
    "    from hops import hdfs\n",
    "    print(tensorboard_hdfs_logdir)\n",
    "    results=[]\n",
    "    for i in range(number_params):\n",
    "        path_to_log=tensorboard_hdfs_logdir+\"/\"\n",
    "        for k in args_dict.keys():\n",
    "            path_to_log+=k+\"=\"+str(args_dict[k][i])+\".\"\n",
    "        path_to_log+=\"log\"\n",
    "        print(\"Path to log: \")\n",
    "        print(path_to_log)\n",
    "        raw = spark.read.csv(path_to_log, sep=\"\\n\")\n",
    "        #raw.show(10)\n",
    "        #raw.count()\n",
    "        r = raw.rdd.flatMap(lambda v: get_accuracy(v)).collect()\n",
    "        results.extend(r)\n",
    "\n",
    "    #print(results)\n",
    "    return [float(res) for res in results]\n",
    "\n",
    "def execute_all(population_dict):\n",
    "    from hops import tflauncher\n",
    "    number_params=[len(v) for v in population_dict.values()][0]\n",
    "    tensorboard_hdfs_logdir = tflauncher.launch(spark, wrapper, population_dict)\n",
    "    return get_all_accuracies(tensorboard_hdfs_logdir, population_dict,number_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary algorithm for hyperparameter optimization\n",
    "To run code just adapt the last fuction (parse_to_dict) to include the items you wanna optimize\n",
    "Also adapt the bounds and types in the main section to reflect the parameters you wanna optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Differential evolution algorithm extended to allow for categorical and integer values for optimization of hyperparameter\n",
    "space in Neural Networks, including an option for parallelization.\n",
    "\n",
    "This algorithm will create a full population to be evaluated, unlike typical differential evolution where each\n",
    "individual get compared and selected sequentially. This allows the user to send a whole population of parameters\n",
    "to a cluster and run computations in parallel, after which each individual gets evaluated with their respective\n",
    "target or trial vector.\n",
    "\n",
    "User will have to define:\n",
    "- Objective function to be optimized\n",
    "- Bounds of each parameter (all possible values)\n",
    "- The Types of each parameter, in order to be able to evaluate categorical, integer or floating values.\n",
    "- Direction of the optimization, i.e. maximization or minimization\n",
    "- Number of iterations, i.e. the amount of generations the algorithm will run\n",
    "- The population size, rule of thumb is to take between 5-10 time the amount of parameters to optimize\n",
    "- Mutation faction between [0, 2)\n",
    "- Crossover between [0, 1], the higher the value the more mutated values will crossover\n",
    "'''\n",
    "\n",
    "import random\n",
    "\n",
    "class DifferentialEvolution:\n",
    "    _types = ['float', 'int', 'cat']\n",
    "    _generation = 0\n",
    "    _scores = []\n",
    "\n",
    "    def __init__(self, objective_function, parbounds, types, direction = 'max', maxiter=10, popsize=10, mutationfactor=0.5, crossover=0.7):\n",
    "        self.objective_function = objective_function\n",
    "        self.parbounds = parbounds\n",
    "        self.direction = direction\n",
    "        self.types = types\n",
    "        self.maxiter = maxiter\n",
    "        self.n = popsize\n",
    "        self.F = mutationfactor\n",
    "        self.CR = crossover\n",
    "\n",
    "        #self.m = -1 if maximize else 1\n",
    "\n",
    "    # run differential evolution algorithms\n",
    "    def solve(self):\n",
    "        # initialise generation based on individual representation\n",
    "        population, bounds = self._population_initialisation()\n",
    "        print(population)\n",
    "        for _ in range(self.maxiter):\n",
    "            donor_population = self._mutation(population, bounds)\n",
    "            trial_population = self._recombination(population, donor_population)\n",
    "            population = self._selection(population, trial_population)\n",
    "\n",
    "            new_gen_avg = sum(self._scores)/self.n\n",
    "\n",
    "            if self.direction == 'max':\n",
    "                new_gen_best = max(self._scores)\n",
    "            else:\n",
    "                new_gen_best = min(self._scores)\n",
    "            new_gen_best_param = self._parse_back(population[self._scores.index(new_gen_best)])\n",
    "\n",
    "            print(\"Generation: \", self._generation, \" || \", \"Average score: \", new_gen_avg,\n",
    "                  \", best score: \", new_gen_best, \"best param: \", new_gen_best_param)\n",
    "\n",
    "        parsed_back_population = []\n",
    "        for indiv in population:\n",
    "            parsed_back_population.append(self._parse_back(indiv))\n",
    "\n",
    "        return parsed_back_population, self._scores\n",
    "\n",
    "    # define bounds of each individual depending on type\n",
    "    def _individual_representation(self):\n",
    "        bounds = []\n",
    "\n",
    "        for index, item in enumerate(self.types):\n",
    "            b =()\n",
    "            # if categorical then take bounds from 0 to number of items\n",
    "            if item == self._types[2]:\n",
    "                b = (0, int(len(self.parbounds[index]) - 1))\n",
    "            # if float/int then take given bounds\n",
    "            else:\n",
    "                b = self.parbounds[index]\n",
    "            bounds.append(b)\n",
    "        return bounds\n",
    "\n",
    "    # initialise population\n",
    "    def _population_initialisation(self):\n",
    "        population = []\n",
    "        num_parameters = len(self.parbounds)\n",
    "        for i in range(self.n):\n",
    "            indiv = []\n",
    "            bounds = self._individual_representation()\n",
    "\n",
    "            for i in range(num_parameters):\n",
    "                indiv.append(random.uniform(bounds[i][0], bounds[i][1]))\n",
    "            indiv = self._ensure_bounds(indiv, bounds)\n",
    "            population.append(indiv)\n",
    "        return population, bounds\n",
    "\n",
    "    # ensure that any mutated individual is within bounds\n",
    "    def _ensure_bounds(self, indiv, bounds):\n",
    "        indiv_correct = []\n",
    "\n",
    "        for i in range(len(indiv)):\n",
    "            par = indiv[i]\n",
    "\n",
    "            # check if param is within bounds\n",
    "            lowerbound = bounds[i][0]\n",
    "            upperbound = bounds[i][1]\n",
    "            if par < lowerbound:\n",
    "                par = lowerbound\n",
    "            elif par > upperbound:\n",
    "                par = upperbound\n",
    "\n",
    "            # check if param needs rounding\n",
    "            if self.types[i] != 'float':\n",
    "                par = int(round(par))\n",
    "            indiv_correct.append(par)\n",
    "        return indiv_correct\n",
    "\n",
    "    # create donor population based on mutation of three vectors\n",
    "    def _mutation(self, population, bounds):\n",
    "        donor_population = []\n",
    "        for i in range(self.n):\n",
    "\n",
    "            indiv_indices = list(range(0, self.n))\n",
    "            indiv_indices.remove(i)\n",
    "\n",
    "            candidates = random.sample(indiv_indices, 3)\n",
    "            x_1 = population[candidates[0]]\n",
    "            x_2 = population[candidates[1]]\n",
    "            x_3 = population[candidates[2]]\n",
    "\n",
    "            # substracting the second from the third candidate\n",
    "            x_diff = [x_2_i - x_3_i for x_2_i, x_3_i in zip(x_2, x_3)]\n",
    "            donor_vec = [x_1_i + self.F*x_diff_i for x_1_i, x_diff_i in zip (x_1, x_diff)]\n",
    "            donor_vec = self._ensure_bounds(donor_vec, bounds)\n",
    "            donor_population.append(donor_vec)\n",
    "\n",
    "        return donor_population\n",
    "\n",
    "    # recombine donor vectors according to crossover probability\n",
    "    def _recombination(self, population, donor_population):\n",
    "        trial_population = []\n",
    "        for k in range(self.n):\n",
    "            target_vec = population[k]\n",
    "            donor_vec = donor_population[k]\n",
    "            trial_vec = []\n",
    "            for p in range(len(self.parbounds)):\n",
    "                crossover = random.random()\n",
    "\n",
    "                # if random number is below set crossover probability do recombination\n",
    "                if crossover <= self.CR:\n",
    "                    trial_vec.append(donor_vec[p])\n",
    "                else:\n",
    "                    trial_vec.append(target_vec[p])\n",
    "            trial_population.append(trial_vec)\n",
    "        return trial_population\n",
    "\n",
    "    # select the best individuals from each generation\n",
    "    def _selection(self, population, trial_population):\n",
    "        # Calculate trial vectors and target vectors and select next generation\n",
    "\n",
    "        if self._generation == 0:\n",
    "            parsed_population = []\n",
    "            for target_vec in population:\n",
    "                parsed_target_vec = self._parse_back(target_vec)\n",
    "                parsed_population.append(parsed_target_vec)\n",
    "\n",
    "            parsed_population = self._parse_to_dict(parsed_population)\n",
    "            self._scores = self.objective_function(parsed_population)\n",
    "\n",
    "        parsed_trial_population = []\n",
    "        for index, trial_vec in enumerate(trial_population):\n",
    "            parsed_trial_vec = self._parse_back(trial_vec)\n",
    "            parsed_trial_population.append(parsed_trial_vec)\n",
    "\n",
    "        parsed_trial_population =  self._parse_to_dict(parsed_trial_population)\n",
    "        trial_population_scores = self.objective_function(parsed_trial_population)\n",
    "\n",
    "        for i in range(self.n):\n",
    "            trial_vec_score_i = trial_population_scores[i]\n",
    "            target_vec_score_i = self._scores[i]\n",
    "            if self.direction == 'max':\n",
    "                if trial_vec_score_i > target_vec_score_i:\n",
    "                    self._scores[index] = trial_vec_score_i\n",
    "                    population[index] = trial_vec\n",
    "            else:\n",
    "                if trial_vec_score_i < target_vec_score_i:\n",
    "                    self._scores[index] = trial_vec_score_i\n",
    "                    population[index] = trial_vec\n",
    "\n",
    "        self._generation += 1\n",
    "\n",
    "        return population\n",
    "\n",
    "    # parse the converted values back to original\n",
    "    def _parse_back(self, individual):\n",
    "        original_representation = []\n",
    "        for index, parameter in enumerate(individual):\n",
    "            if self.types[index] == self._types[2]:\n",
    "                original_representation.append(self.parbounds[index][parameter])\n",
    "            else:\n",
    "\n",
    "                original_representation.append(parameter)\n",
    "\n",
    "        return original_representation\n",
    "\n",
    "    # for parallelization purposes one can parse the population from a list to a  dictionary format\n",
    "    # User only has to add the parameters he wants to optimize to population_dict\n",
    "    def _parse_to_dict(self, population):\n",
    "        population_dict = {'learning_rate': [], 'dropout': []}\n",
    "        for indiv in population:\n",
    "            population_dict['learning_rate'].append(indiv[0])\n",
    "            population_dict['dropout'].append(indiv[1])\n",
    "\n",
    "        return population_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_evo = DifferentialEvolution(execute_all,[(0.005, 0.1),(0.1, 0.9)], ['cat', 'float'], direction='max', maxiter=2,popsize=4)\n",
    "\n",
    "results = diff_evo.solve()\n",
    "\n",
    "print(\"Population: \", results[0])\n",
    "print(\"Scores: \", results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
